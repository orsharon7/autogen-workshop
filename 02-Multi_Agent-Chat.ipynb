{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Multi Agent Chat](https://microsoft.github.io/autogen/docs/Examples/#automated-multi-agent-chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) [Automated Task Solving by Group Chat (with 3 group member agents and 1 manager agent)](https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "\n",
    "# Set your API endpoints\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\"OAI_CONFIG_LIST\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up local command code executor\n",
    "import tempfile\n",
    "from autogen import ConversableAgent\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "\n",
    "# Create a temporary directory to store the code files.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Create a local command line code executor.\n",
    "executor = LocalCommandLineCodeExecutor(\n",
    "    timeout=10,  # Timeout for each code execution in seconds.\n",
    "    work_dir=temp_dir.name,  # Use the temporary directory to store the code files.\n",
    ")\n",
    "\n",
    "# Create an agent with code executor configuration.\n",
    "code_executor_agent = ConversableAgent(\n",
    "    \"code_executor_agent\",\n",
    "    llm_config=False,  # Turn off LLM for this agent.\n",
    "    code_execution_config={\"executor\": executor},  # Use the local command line code executor.\n",
    "    human_input_mode=\"ALWAYS\",  # Always/Never take human input for this agent for safety.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Agents\n",
    "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 2,\n",
    "        \"work_dir\": \"groupchat\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    "    human_input_mode=\"TERMINATE\",\n",
    ")\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User_proxy\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Coder\n",
      "\u001b[0m\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "**Plan**\n",
      "\n",
      "1. **Search arXiv**: Use a Python script to search for recent papers about \"GPT-4\" on arXiv.\n",
      "2. **Collect paper information**: Parse the response to find relevant details about the latest paper.\n",
      "3. **Identify potential applications**: Read the abstract of the paper to identify potential applications of GPT-4 in software.\n",
      "\n",
      "**Step 1: Search arXiv**  \n",
      "I'll use the arXiv API to search for the latest papers on GPT-4. \n",
      "\n",
      "```python\n",
      "# filename: search_gpt4_arxiv.py\n",
      "import requests\n",
      "\n",
      "# Define the search query and sort by submission date in descending order\n",
      "search_query = \"gpt-4\"\n",
      "url = f\"http://export.arxiv.org/api/query?search_query=all:{search_query}&sortBy=submittedDate&sortOrder=descending&max_results=1\"\n",
      "\n",
      "response = requests.get(url)\n",
      "\n",
      "# Print the response content\n",
      "print(response.content.decode('utf-8'))\n",
      "```\n",
      "\n",
      "Please execute the above script and provide the output so I can identify the latest paper on GPT-4. Once the paper details (title, abstract, etc.) are retrieved, I will read the abstract to identify and explain the potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User_proxy\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3Agpt-4%26id_list%3D%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=all:gpt-4&amp;id_list=&amp;start=0&amp;max_results=1</title>\n",
      "  <id>http://arxiv.org/api/kRx2JtyaBPcZxyFGxvQUuEnTFkQ</id>\n",
      "  <updated>2024-06-25T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">2081</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2406.16842v1</id>\n",
      "    <updated>2024-06-24T17:47:55Z</updated>\n",
      "    <published>2024-06-24T17:47:55Z</published>\n",
      "    <title>Exploring Factual Entailment with NLI: A News Media Study</title>\n",
      "    <summary>  We explore the relationship between factuality and Natural Language Inference\n",
      "(NLI) by introducing FactRel -- a novel annotation scheme that models\n",
      "\\textit{factual} rather than \\textit{textual} entailment, and use it to\n",
      "annotate a dataset of naturally occurring sentences from news articles. Our\n",
      "analysis shows that 84\\% of factually supporting pairs and 63\\% of factually\n",
      "undermining pairs do not amount to NLI entailment or contradiction,\n",
      "respectively, suggesting that factual relationships are more apt for analyzing\n",
      "media discourse. We experiment with models for pairwise classification on the\n",
      "new dataset, and find that in some cases, generating synthetic data with GPT-4\n",
      "on the basis of the annotated dataset can improve performance. Surprisingly,\n",
      "few-shot learning with GPT-4 yields strong results on par with medium LMs\n",
      "(DeBERTa) trained on the labelled dataset. We hypothesize that these results\n",
      "indicate the fundamental dependence of this task on both world knowledge and\n",
      "advanced reasoning abilities.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Guy Mor-Lan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Effi Levi</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Presented at *SEM 2024</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2406.16842v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2406.16842v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Product_manager\n",
      "\u001b[0m\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "### Latest Paper on GPT-4\n",
      "\n",
      "#### Paper Details:\n",
      "- **Title**: Exploring Factual Entailment with NLI: A News Media Study\n",
      "- **Authors**: Guy Mor-Lan, Effi Levi\n",
      "- **Published Date**: June 24, 2024\n",
      "- **URL**: [Paper Link](http://arxiv.org/abs/2406.16842v1)\n",
      "- **PDF**: [Download PDF](http://arxiv.org/pdf/2406.16842v1)\n",
      "- **Abstract**:\n",
      "  ```\n",
      "  We explore the relationship between factuality and Natural Language Inference(NLI) by introducing FactRel -- a novel annotation scheme that models factual rather than textual entailment and uses it to annotate a dataset of naturally occurring sentences from news articles. Our analysis shows that 84% of factually supporting pairs and 63% of factually undermining pairs do not amount to NLI entailment or contradiction, respectively, suggesting that factual relationships are more apt for analyzing media discourse. We experiment with models for pairwise classification on the new dataset, and find that in some cases, generating synthetic data with GPT-4 on the basis of the annotated dataset can improve performance. Surprisingly, few-shot learning with GPT-4 yields strong results on par with medium LMs (DeBERTa) trained on the labelled dataset. We hypothesize that these results indicate the fundamental dependence of this task on both world knowledge and advanced reasoning abilities.\n",
      "  ```\n",
      "\n",
      "### Potential Applications in Software:\n",
      "Based on the abstract, here are some potential software applications for GPT-4 derived from this paper:\n",
      "\n",
      "1. **Media Fact-Checking Tools**:\n",
      "   - **Application**: Develop browser extensions or standalone applications that automatically evaluate the factual accuracy of news articles.\n",
      "   - **Functionality**: Use GPT-4-based models to classify and analyze factual statements in real-time, providing users with fact-checking reports.\n",
      "\n",
      "2. **Automated Content Verification**:\n",
      "   - **Application**: Implement automated verification systems within content management systems for journalism and media organizations.\n",
      "   - **Functionality**: Assist editors and journalists by flagging potentially false or misleading information before publication.\n",
      "\n",
      "3. **Advanced Information Retrieval Systems**:\n",
      "   - **Application**: Enhance search engines and databases with fact-based retrieval capabilities.\n",
      "   - **Functionality**: Allow users to retrieve information based on factual entailment, not just keyword matching, providing more accurate and trustworthy search results.\n",
      "\n",
      "4. **Educational Tools**:\n",
      "   - **Application**: Create educational software geared towards critical thinking and media literacy.\n",
      "   - **Functionality**: Use GPT-4 to generate scenarios and datasets for students to practice discerning factual from non-factual information.\n",
      "\n",
      "5. **Social Media Analysis and Monitoring**:\n",
      "   - **Application**: Develop tools for monitoring social media platforms for misinformation.\n",
      "   - **Functionality**: Analyze posts and comments for factual accuracy, alerting platform moderators of potential misinformation.\n",
      "\n",
      "6. **Legal and Compliance Software**:\n",
      "   - **Application**: Aid legal professionals by providing fact-checking tools to verify the authenticity of documents and claims.\n",
      "   - **Functionality**: Use GPT-4 to cross-reference facts in legal texts with verified sources, assisting in building stronger cases.\n",
      "\n",
      "7. **Health Information Verification**:\n",
      "   - **Application**: Implement fact-checking systems within healthcare information portals.\n",
      "   - **Functionality**: Ensure that patients and healthcare professionals access accurate and factual health information by verifying user-generated content.\n",
      "\n",
      "8. **News Aggregator Platforms**:\n",
      "   - **Application**: Improve news aggregator platforms by incorporating factual entailment verification.\n",
      "   - **Functionality**: Highlight and prioritize news stories verified for accuracy, helping users trust the content they consume.\n",
      "\n",
      "### Conclusion\n",
      "The identified potential applications showcase how GPT-4's ability to handle fact-based reasoning can significantly enhance the reliability and trustworthiness of information across various domains. Whether in media, education, legal, or health fields, integrating GPT-4 into software solutions can dramatically reduce the spread of misinformation and improve the accuracy of content consumed by users.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Coder\n",
      "\u001b[0m\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'Find a latest paper about gpt-4 on arxiv and find its potential applications in software.', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}, {'content': '**Plan**\\n\\n1. **Search arXiv**: Use a Python script to search for recent papers about \"GPT-4\" on arXiv.\\n2. **Collect paper information**: Parse the response to find relevant details about the latest paper.\\n3. **Identify potential applications**: Read the abstract of the paper to identify potential applications of GPT-4 in software.\\n\\n**Step 1: Search arXiv**  \\nI\\'ll use the arXiv API to search for the latest papers on GPT-4. \\n\\n```python\\n# filename: search_gpt4_arxiv.py\\nimport requests\\n\\n# Define the search query and sort by submission date in descending order\\nsearch_query = \"gpt-4\"\\nurl = f\"http://export.arxiv.org/api/query?search_query=all:{search_query}&sortBy=submittedDate&sortOrder=descending&max_results=1\"\\n\\nresponse = requests.get(url)\\n\\n# Print the response content\\nprint(response.content.decode(\\'utf-8\\'))\\n```\\n\\nPlease execute the above script and provide the output so I can identify the latest paper on GPT-4. Once the paper details (title, abstract, etc.) are retrieved, I will read the abstract to identify and explain the potential applications in software.', 'name': 'Coder', 'role': 'user'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3Agpt-4%26id_list%3D%26start%3D0%26max_results%3D1\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=all:gpt-4&amp;id_list=&amp;start=0&amp;max_results=1</title>\\n  <id>http://arxiv.org/api/kRx2JtyaBPcZxyFGxvQUuEnTFkQ</id>\\n  <updated>2024-06-25T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">2081</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/2406.16842v1</id>\\n    <updated>2024-06-24T17:47:55Z</updated>\\n    <published>2024-06-24T17:47:55Z</published>\\n    <title>Exploring Factual Entailment with NLI: A News Media Study</title>\\n    <summary>  We explore the relationship between factuality and Natural Language Inference\\n(NLI) by introducing FactRel -- a novel annotation scheme that models\\n\\\\textit{factual} rather than \\\\textit{textual} entailment, and use it to\\nannotate a dataset of naturally occurring sentences from news articles. Our\\nanalysis shows that 84\\\\% of factually supporting pairs and 63\\\\% of factually\\nundermining pairs do not amount to NLI entailment or contradiction,\\nrespectively, suggesting that factual relationships are more apt for analyzing\\nmedia discourse. We experiment with models for pairwise classification on the\\nnew dataset, and find that in some cases, generating synthetic data with GPT-4\\non the basis of the annotated dataset can improve performance. Surprisingly,\\nfew-shot learning with GPT-4 yields strong results on par with medium LMs\\n(DeBERTa) trained on the labelled dataset. We hypothesize that these results\\nindicate the fundamental dependence of this task on both world knowledge and\\nadvanced reasoning abilities.\\n</summary>\\n    <author>\\n      <name>Guy Mor-Lan</name>\\n    </author>\\n    <author>\\n      <name>Effi Levi</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Presented at *SEM 2024</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2406.16842v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2406.16842v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n\\n', 'role': 'assistant'}, {'content': \"### Latest Paper on GPT-4\\n\\n#### Paper Details:\\n- **Title**: Exploring Factual Entailment with NLI: A News Media Study\\n- **Authors**: Guy Mor-Lan, Effi Levi\\n- **Published Date**: June 24, 2024\\n- **URL**: [Paper Link](http://arxiv.org/abs/2406.16842v1)\\n- **PDF**: [Download PDF](http://arxiv.org/pdf/2406.16842v1)\\n- **Abstract**:\\n  ```\\n  We explore the relationship between factuality and Natural Language Inference(NLI) by introducing FactRel -- a novel annotation scheme that models factual rather than textual entailment and uses it to annotate a dataset of naturally occurring sentences from news articles. Our analysis shows that 84% of factually supporting pairs and 63% of factually undermining pairs do not amount to NLI entailment or contradiction, respectively, suggesting that factual relationships are more apt for analyzing media discourse. We experiment with models for pairwise classification on the new dataset, and find that in some cases, generating synthetic data with GPT-4 on the basis of the annotated dataset can improve performance. Surprisingly, few-shot learning with GPT-4 yields strong results on par with medium LMs (DeBERTa) trained on the labelled dataset. We hypothesize that these results indicate the fundamental dependence of this task on both world knowledge and advanced reasoning abilities.\\n  ```\\n\\n### Potential Applications in Software:\\nBased on the abstract, here are some potential software applications for GPT-4 derived from this paper:\\n\\n1. **Media Fact-Checking Tools**:\\n   - **Application**: Develop browser extensions or standalone applications that automatically evaluate the factual accuracy of news articles.\\n   - **Functionality**: Use GPT-4-based models to classify and analyze factual statements in real-time, providing users with fact-checking reports.\\n\\n2. **Automated Content Verification**:\\n   - **Application**: Implement automated verification systems within content management systems for journalism and media organizations.\\n   - **Functionality**: Assist editors and journalists by flagging potentially false or misleading information before publication.\\n\\n3. **Advanced Information Retrieval Systems**:\\n   - **Application**: Enhance search engines and databases with fact-based retrieval capabilities.\\n   - **Functionality**: Allow users to retrieve information based on factual entailment, not just keyword matching, providing more accurate and trustworthy search results.\\n\\n4. **Educational Tools**:\\n   - **Application**: Create educational software geared towards critical thinking and media literacy.\\n   - **Functionality**: Use GPT-4 to generate scenarios and datasets for students to practice discerning factual from non-factual information.\\n\\n5. **Social Media Analysis and Monitoring**:\\n   - **Application**: Develop tools for monitoring social media platforms for misinformation.\\n   - **Functionality**: Analyze posts and comments for factual accuracy, alerting platform moderators of potential misinformation.\\n\\n6. **Legal and Compliance Software**:\\n   - **Application**: Aid legal professionals by providing fact-checking tools to verify the authenticity of documents and claims.\\n   - **Functionality**: Use GPT-4 to cross-reference facts in legal texts with verified sources, assisting in building stronger cases.\\n\\n7. **Health Information Verification**:\\n   - **Application**: Implement fact-checking systems within healthcare information portals.\\n   - **Functionality**: Ensure that patients and healthcare professionals access accurate and factual health information by verifying user-generated content.\\n\\n8. **News Aggregator Platforms**:\\n   - **Application**: Improve news aggregator platforms by incorporating factual entailment verification.\\n   - **Functionality**: Highlight and prioritize news stories verified for accuracy, helping users trust the content they consume.\\n\\n### Conclusion\\nThe identified potential applications showcase how GPT-4's ability to handle fact-based reasoning can significantly enhance the reliability and trustworthiness of information across various domains. Whether in media, education, legal, or health fields, integrating GPT-4 into software solutions can dramatically reduce the spread of misinformation and improve the accuracy of content consumed by users.\", 'name': 'Product_manager', 'role': 'user'}, {'content': 'TERMINATE', 'name': 'Coder', 'role': 'user'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start chat\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
    ")\n",
    "# type exit to terminate the chat\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
